diff --git a/antblock/antblock/envs/ant_v5.py b/antblock/antblock/envs/ant_v5.py
index acd18f5..2a55f08 100644
--- a/antblock/antblock/envs/ant_v5.py
+++ b/antblock/antblock/envs/ant_v5.py
@@ -215,7 +215,7 @@ class AntBlockEnv(MujocoEnv, utils.EzPickle):
             exclude_current_positions_from_observation
         )
 
-        obs_shape = 27
+        obs_shape = 29
         if not exclude_current_positions_from_observation:
             obs_shape += 2
         if use_contact_forces:
diff --git a/test2.py b/test2.py
index 5b57700..d51122e 100644
--- a/test2.py
+++ b/test2.py
@@ -19,7 +19,7 @@ def parse_args():
     parser = argparse.ArgumentParser()
     parser.add_argument("--exp-name", type=str, default=os.path.basename(__file__).rstrip(".py"),
         help="the name of this experiment")
-    parser.add_argument("--gym-id", type=str, default="antblock",
+    parser.add_argument("--gym-id", type=str, default="Ant-v4",
         help="the id of the gym environment")
     parser.add_argument("--learning-rate", type=float, default=3e-4,
         help="the learning rate of the optimizer")
@@ -80,7 +80,7 @@ def parse_args():
 
 def make_env(gym_id, seed, idx, capture_video, run_name):
     def thunk():
-        env = gym.make(gym_id,render_mode="human")
+        env = gym.make(gym_id,render_mode="None")
         env = gym.wrappers.RecordEpisodeStatistics(env)
         if capture_video:
             if idx == 0:
@@ -189,8 +189,8 @@ if __name__ == "__main__":
 
     for update in range(1, num_updates + 1):
         # Annealing the rate if instructed to do so.
-        envs.envs[0].model.geom_size[14][2] = np.random.normal(0.3, 0.2, 1)
-        envs.envs[0].model.body_pos[14][2]=envs.envs[0].model.geom_size[14][2]
+        # envs.envs[0].model.geom_size[14][2] = np.random.normal(0.3, 0.2, 1)
+        # envs.envs[0].model.body_pos[14][2]=envs.envs[0].model.geom_size[14][2]
         if args.anneal_lr:
             frac = 1.0 - (update - 1.0) / num_updates
             lrnow = frac * args.learning_rate
@@ -213,13 +213,13 @@ if __name__ == "__main__":
             rewards[step] = torch.tensor(reward).to(device).view(-1)
             next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)
 
-            # for item in info:
-            #     print(item)
-            #     if "episode" in item.keys():
-            #         print(f"global_step={global_step}, episodic_return={item['episode']['r']}")
-            #         writer.add_scalar("charts/episodic_return", item["episode"]["r"], global_step)
-            #         writer.add_scalar("charts/episodic_length", item["episode"]["l"], global_step)
-            #         break
+            for item in info:
+                print(item)
+                if "episode" in item.keys():
+                    print(f"global_step={global_step}, episodic_return={item['episode']['r']}")
+                    writer.add_scalar("charts/episodic_return", item["episode"]["r"], global_step)
+                    writer.add_scalar("charts/episodic_length", item["episode"]["l"], global_step)
+                    break
 
         # bootstrap value if not done
         with torch.no_grad():
