# PPO-ant
Implementation of PPO on custom environment derived from the Ant-v4 environment in OpenAI gym to learn to traverse template obstacles.
